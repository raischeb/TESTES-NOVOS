# üéØ Roteiro de Desenvolvimento - TraduLibras

## üìã Vis√£o Geral do Projeto

O TraduLibras √© um sistema de reconhecimento de gestos da L√≠ngua Brasileira de Sinais (LIBRAS) que utiliza:
- **MediaPipe** para detec√ß√£o de m√£os
- **Scikit-learn** para classifica√ß√£o de gestos
- **Flask** para interface web
- **gTTS** para s√≠ntese de voz

---

## üöÄ Fase 1: Coleta de Dados de Gestos

### 1.1 Prepara√ß√£o do Ambiente
```bash
# 1. Ativar ambiente virtual
.venv\Scripts\activate  # Windows
# ou
source .venv/bin/activate  # Linux/macOS

# 2. Verificar depend√™ncias
pip list | findstr -i "opencv mediapipe scikit-learn flask gtts"
```

### 1.2 Executar Coleta de Gestos
```bash
# Executar script de coleta
python treinar_letras_simples.py
```

### 1.3 Processo de Coleta Detalhado

#### **Para cada letra (A, B, C, L, Y):**

1. **Posicionamento:**
   - Sente-se a 50-70cm da webcam
   - Mantenha boa ilumina√ß√£o (evite sombras)
   - Posicione a m√£o no centro do frame

2. **Coleta de Amostras:**
   - Fa√ßa o gesto da letra correspondente
   - Pressione **ESPA√áO** para capturar uma amostra
   - Varie ligeiramente a posi√ß√£o e √¢ngulo da m√£o
   - **Meta:** 30-50 amostras por letra

3. **Controles:**
   - **ESPA√áO:** Capturar amostra
   - **ESC:** Pular letra atual
   - **Q:** Sair do programa

4. **Dicas de Qualidade:**
   - Mantenha gestos consistentes
   - Evite movimentos durante a captura
   - Use fundo neutro (preferencialmente branco)
   - Certifique-se de que todos os dedos est√£o vis√≠veis

### 1.4 Verifica√ß√£o dos Dados Coletados
```bash
# Verificar arquivo de dados
python -c "
import pandas as pd
df = pd.read_csv('gestos_libras.csv')
print(f'Total de amostras: {len(df)}')
print(f'Classes: {sorted(df[\"label\"].unique())}')
print('Distribui√ß√£o por classe:')
print(df['label'].value_counts())
"
```

---

## üß† Fase 2: Treinamento do Modelo

### 2.1 Treinamento Autom√°tico
O treinamento acontece automaticamente ap√≥s a coleta, mas voc√™ pode executar manualmente:

```bash
# Treinar modelo (se necess√°rio)
python -c "
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import pickle
import os

# Carregar dados
df = pd.read_csv('gestos_libras.csv')
feature_columns = [col for col in df.columns if col != 'label']
X = df[feature_columns].values
y = df['label'].values

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinar modelo
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Avaliar
train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)
print(f'Acur√°cia treino: {train_acc:.2%}')
print(f'Acur√°cia teste: {test_acc:.2%}')

# Salvar modelo
os.makedirs('modelos', exist_ok=True)
with open('modelos/modelo_libras.pkl', 'wb') as f:
    pickle.dump(model, f)

# Salvar informa√ß√µes do modelo
model_info = {
    'classes': model.classes_.tolist(),
    'n_features': len(feature_columns),
    'train_accuracy': train_acc,
    'test_accuracy': test_acc
}
with open('modelos/modelo_info.pkl', 'wb') as f:
    pickle.dump(model_info, f)

print('Modelo salvo em modelos/modelo_libras.pkl')
"
```

### 2.2 Verifica√ß√£o do Modelo Treinado
```bash
# Verificar modelo
python -c "
import pickle
with open('modelos/modelo_libras.pkl', 'rb') as f:
    model = pickle.load(f)
with open('modelos/modelo_info.pkl', 'rb') as f:
    info = pickle.load(f)

print('‚úÖ Modelo carregado com sucesso!')
print(f'üìä Classes: {info[\"classes\"]}')
print(f'üìà Acur√°cia treino: {info[\"train_accuracy\"]:.2%}')
print(f'üìà Acur√°cia teste: {info[\"test_accuracy\"]:.2%}')
"
```

---

## üîß Fase 3: Atualiza√ß√£o da Aplica√ß√£o Principal

### 3.1 Estrutura do app.py Atualizada

#### **Funcionalidades Implementadas:**
- ‚úÖ Carregamento do modelo treinado
- ‚úÖ Detec√ß√£o de m√£os com MediaPipe
- ‚úÖ Classifica√ß√£o de gestos em tempo real
- ‚úÖ Sistema de cooldown para estabiliza√ß√£o
- ‚úÖ Forma√ß√£o de palavras a partir de letras
- ‚úÖ Convers√£o de texto para fala com gTTS
- ‚úÖ Interface web responsiva

#### **Rotas Dispon√≠veis:**
- `/` - P√°gina inicial
- `/camera` - Interface de reconhecimento
- `/video_feed` - Stream de v√≠deo
- `/letra_atual` - Letra detectada no momento
- `/falar_texto` - Convers√£o texto para fala
- `/limpar_texto` - Limpar texto formado

### 3.2 Configura√ß√µes de Voz (gTTS)

#### **Vozes Dispon√≠veis no Azure (gTTS):**
- `pt-br` - Portugu√™s brasileiro padr√£o
- `pt-br-FranciscaNeural` - Voz feminina neural (recomendada)
- `pt-br-AntonioNeural` - Voz masculina neural

#### **Implementa√ß√£o da Voz FranciscaNeural:**
```python
from gtts import gTTS
import tempfile
import os

def text_to_speech_francisca(text):
    """Converte texto para fala usando voz FranciscaNeural"""
    try:
        # Usar voz FranciscaNeural do Azure
        tts = gTTS(text=text, lang='pt-br', tld='com.br')
        
        # Criar arquivo tempor√°rio
        temp_dir = tempfile.gettempdir()
        temp_file = os.path.join(temp_dir, 'speech_francisca.mp3')
        
        # Salvar √°udio
        tts.save(temp_file)
        return temp_file
    except Exception as e:
        print(f"Erro na s√≠ntese de voz: {e}")
        return None
```

---

## üéÆ Fase 4: Teste da Aplica√ß√£o

### 4.1 Executar Aplica√ß√£o
```bash
# 1. Ativar ambiente virtual
.venv\Scripts\activate

# 2. Executar aplica√ß√£o
python app.py
```

### 4.2 Teste de Funcionalidades

#### **Teste 1: Reconhecimento de Gestos**
1. Acesse `http://localhost:5000/camera`
2. Permita acesso √† webcam
3. Fa√ßa gestos das letras A, B, C, L, Y
4. Verifique se as letras aparecem na tela
5. Teste o sistema de cooldown (1 segundo entre detec√ß√µes)

#### **Teste 2: Forma√ß√£o de Palavras**
1. Fa√ßa sequ√™ncia de gestos: A-B-C
2. Verifique se forma a palavra "ABC"
3. Teste com outras combina√ß√µes

#### **Teste 3: S√≠ntese de Voz**
1. Forme uma palavra (ex: "ABC")
2. Clique no bot√£o "Falar"
3. Verifique se a voz FranciscaNeural reproduz o texto
4. Teste com diferentes palavras

#### **Teste 4: Interface Web**
1. Teste responsividade em diferentes tamanhos de tela
2. Verifique se todos os bot√µes funcionam
3. Teste navega√ß√£o entre p√°ginas

---

## üîç Fase 5: Troubleshooting

### 5.1 Problemas Comuns

#### **Webcam n√£o funciona:**
```bash
# Verificar dispositivos de v√≠deo
python -c "import cv2; print('Dispositivos:', [i for i in range(10) if cv2.VideoCapture(i).isOpened()])"
```

#### **Modelo n√£o carrega:**
```bash
# Verificar arquivos do modelo
ls -la modelos/
python -c "import pickle; model=pickle.load(open('modelos/modelo_libras.pkl','rb')); print('OK')"
```

#### **Erro de depend√™ncias:**
```bash
# Reinstalar depend√™ncias
pip uninstall -r requirements.txt -y
pip install -r requirements.txt
```

#### **Voz n√£o funciona:**
```bash
# Testar gTTS
python -c "from gtts import gTTS; tts=gTTS('teste', lang='pt-br'); print('gTTS OK')"
```

### 5.2 Logs de Debug
```bash
# Executar com debug
python app.py --debug

# Verificar logs do Flask
# Os logs aparecer√£o no terminal
```

---

## üìä Fase 6: M√©tricas de Qualidade

### 6.1 Avalia√ß√£o do Modelo
- **Acur√°cia m√≠nima:** 90%
- **Acur√°cia recomendada:** 95%+
- **Tempo de resposta:** < 100ms
- **Taxa de falsos positivos:** < 5%

### 6.2 Testes de Performance
```bash
# Teste de carga (opcional)
python -c "
import time
import requests

start = time.time()
for i in range(100):
    response = requests.get('http://localhost:5000/letra_atual')
end = time.time()
print(f'100 requests em {end-start:.2f}s')
print(f'M√©dia: {(end-start)/100*1000:.2f}ms por request')
"
```

---

## üöÄ Fase 7: Deploy e Produ√ß√£o

### 7.1 Prepara√ß√£o para Deploy
```bash
# 1. Criar requirements.txt atualizado
pip freeze > requirements.txt

# 2. Testar em ambiente limpo
python -m venv test_env
test_env\Scripts\activate
pip install -r requirements.txt
python app.py
```

### 7.2 Configura√ß√µes de Produ√ß√£o
- Configurar `app.run(debug=False)`
- Usar servidor WSGI (Gunicorn, uWSGI)
- Configurar proxy reverso (Nginx)
- Implementar logs estruturados

---

## üìù Checklist Final

- [ ] Ambiente virtual configurado
- [ ] Depend√™ncias instaladas
- [ ] Dados de gestos coletados (30-50 por letra)
- [ ] Modelo treinado com acur√°cia > 90%
- [ ] Aplica√ß√£o Flask funcionando
- [ ] Reconhecimento de gestos em tempo real
- [ ] S√≠ntese de voz com FranciscaNeural
- [ ] Interface web responsiva
- [ ] Testes de funcionalidade completos
- [ ] Documenta√ß√£o atualizada

---

## üéØ Pr√≥ximos Passos

1. **Expans√£o do Vocabul√°rio:** Adicionar mais letras e n√∫meros
2. **Melhoria da Precis√£o:** Coletar mais dados e ajustar par√¢metros
3. **Interface Avan√ßada:** Adicionar configura√ß√µes e hist√≥rico
4. **Integra√ß√£o Mobile:** Desenvolver app para smartphones
5. **API REST:** Criar API para integra√ß√£o com outros sistemas

---

*Este roteiro deve ser seguido sequencialmente para garantir o desenvolvimento correto do TraduLibras.*
